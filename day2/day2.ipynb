{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EdAmfqM2Hv10"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_HK1H_TO7PwZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade langchain_community bs4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9g8cocm76iZ"
      },
      "source": [
        "# 3개의 블로그 포스팅 본문을 Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B9EFK-hk7nwp"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader([\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "    ])\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vodqb9R18Ae0"
      },
      "source": [
        "# 불러온 본문을 Split (Chunking) : recursive text splitter 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V5W59KBK7yGB"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=50,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "splits = []\n",
        "for doc in docs:\n",
        "  splitted_docs = text_splitter.split_documents([doc])\n",
        "  splits.extend(splitted_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq5G2Il99hNf"
      },
      "source": [
        "# Chunks 를 임베딩하여 Vector store 저장: openai 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTSnJZ7W9zk5",
        "outputId": "ccd4a7c4-46be-47dd-e8ca-1580d91abbd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-openai) (0.2.9)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-openai) (1.34.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (0.1.80)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (2.7.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (8.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain-openai) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.1)\n",
            "Downloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
            "Installing collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fkNG1-Xa8i_p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Set the API key\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "embeddings_model = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKkWa_cc-nEN",
        "outputId": "5a5451dd-2f64-4764-bec3-b52a810312f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-0.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting chromadb<0.6.0,>=0.4.0 (from langchain-chroma)\n",
            "  Downloading chromadb-0.5.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting fastapi<1,>=0.95.2 (from langchain-chroma)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.40 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-chroma) (0.2.9)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-chroma) (1.26.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from sentence_transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from sentence_transformers) (2.2.2)\n",
            "Collecting scikit-learn (from sentence_transformers)\n",
            "  Downloading scikit_learn-1.5.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy (from sentence_transformers)\n",
            "  Downloading scipy-1.13.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.15.1 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from sentence_transformers) (0.23.4)\n",
            "Collecting Pillow (from sentence_transformers)\n",
            "  Downloading pillow-10.3.0-cp310-cp310-macosx_10_10_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting build>=1.0.3 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: requests>=2.28 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.32.3)\n",
            "Requirement already satisfied: pydantic>=1.9 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.7.4)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (252 bytes)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-macosx_11_0_universal2.whl.metadata (4.2 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting overrides>=7.3.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting importlib-resources (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading grpcio-1.64.1-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.3 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-macosx_10_12_universal2.whl.metadata (9.5 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.4.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.10.5)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.27.0)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting email_validator>=2.0.0 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading email_validator-2.1.2-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (0.1.80)\n",
            "Requirement already satisfied: sympy in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: idna>=2.0.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma) (3.7)\n",
            "Requirement already satisfied: anyio in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.4.0)\n",
            "Requirement already satisfied: certifi in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from jinja2>=2.11.2->fastapi<1,>=0.95.2->langchain-chroma) (2.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.9.0.post0)\n",
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading google_auth-2.30.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading protobuf-5.27.1-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (65.5.0)\n",
            "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading wrapt-1.16.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from requests>=2.28->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.3.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-macosx_10_12_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading websockets-12.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.2.1)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting zipp>=0.5 (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
            "Downloading langchain_chroma-0.1.1-py3-none-any.whl (8.5 kB)\n",
            "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.5.3-py3-none-any.whl (559 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-macosx_10_9_x86_64.whl (219 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.6/219.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.3.0-cp310-cp310-macosx_10_10_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.0-cp310-cp310-macosx_10_9_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp310-cp310-macosx_10_9_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading bcrypt-4.1.3-cp39-abi3-macosx_10_12_universal2.whl (506 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading email_validator-2.1.2-py3-none-any.whl (30 kB)\n",
            "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Downloading grpcio-1.64.1-cp310-cp310-macosx_12_0_universal2.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
            "\u001b[?25hDownloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-macosx_10_9_x86_64.whl (29 kB)\n",
            "Downloading onnxruntime-1.18.0-cp310-cp310-macosx_11_0_universal2.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp310-cp310-macosx_10_9_x86_64.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.30.0-py2.py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.7/193.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.2/229.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-macosx_10_9_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.6/77.6 kB\u001b[0m \u001b[31m584.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "Downloading uvloop-0.19.0-cp310-cp310-macosx_10_9_x86_64.whl (793 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.9/793.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.22.0-cp310-cp310-macosx_10_12_x86_64.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.0/395.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-macosx_10_9_x86_64.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Downloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
            "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Downloading wrapt-1.16.0-cp310-cp310-macosx_10_9_x86_64.whl (37 kB)\n",
            "Downloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=1853f71c4261ddacd790b137478d540a294b2eac8aa745af5fad2f2148a8198e\n",
            "  Stored in directory: /Users/sol.ty/Library/Caches/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, flatbuffers, zipp, wrapt, websockets, websocket-client, uvloop, uvicorn, ujson, tomli, threadpoolctl, shellingham, scipy, python-multipart, python-dotenv, pyproject_hooks, pyasn1, protobuf, Pillow, overrides, opentelemetry-util-http, oauthlib, mdurl, importlib-resources, humanfriendly, httptools, grpcio, dnspython, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, starlette, scikit-learn, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, googleapis-common-protos, email_validator, deprecated, coloredlogs, build, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, google-auth, typer, opentelemetry-semantic-conventions, opentelemetry-instrumentation, kubernetes, sentence_transformers, opentelemetry-sdk, opentelemetry-instrumentation-asgi, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb, langchain-chroma\n",
            "Successfully installed Pillow-10.3.0 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 build-1.2.1 cachetools-5.3.3 chroma-hnswlib-0.7.3 chromadb-0.5.3 coloredlogs-15.0.1 deprecated-1.2.14 dnspython-2.6.1 email_validator-2.1.2 fastapi-0.111.0 fastapi-cli-0.0.4 flatbuffers-24.3.25 google-auth-2.30.0 googleapis-common-protos-1.63.1 grpcio-1.64.1 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-7.1.0 importlib-resources-6.4.0 kubernetes-30.1.0 langchain-chroma-0.1.1 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.18.0 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 overrides-7.7.0 posthog-3.5.0 protobuf-4.25.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 pypika-0.48.9 pyproject_hooks-1.1.0 python-dotenv-1.0.1 python-multipart-0.0.9 requests-oauthlib-2.0.0 rich-13.7.1 rsa-4.9 scikit-learn-1.5.0 scipy-1.13.1 sentence_transformers-3.0.1 shellingham-1.5.4 starlette-0.37.2 threadpoolctl-3.5.0 tomli-2.0.1 typer-0.12.3 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websocket-client-1.8.0 websockets-12.0 wrapt-1.16.0 zipp-3.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-chroma sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZpCiSZ1j_PKD"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.embeddings.sentence_transformer import (\n",
        "    SentenceTransformerEmbeddings,\n",
        ")\n",
        "\n",
        "# create the open-source embedding function\n",
        "# embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    collection_name=\"sol_day2\",\n",
        "    documents=splits,\n",
        "    embedding=embeddings_model\n",
        "    )\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IenyTjfy-ShY"
      },
      "source": [
        "# User query = ‘agent memory’ 를 받아 관련된 chunks를 retrieve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z84EHsIS_75t",
        "outputId": "4b23a21c-eaf8-450e-dee6-4d964575dd20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content='Memory', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}), Document(page_content='memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}), Document(page_content='Memory can be defined as the processes used to acquire, store, retain, and later retrieve', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}), Document(page_content='Long-term memory: This provides the agent with the capability to retain and recall (infinite)', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})]\n"
          ]
        }
      ],
      "source": [
        "query =  \"agent momory\"\n",
        "searched_docs = vectorstore.similarity_search(query)\n",
        "\n",
        "# print results\n",
        "print(searched_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mPFAeQdAV6p",
        "outputId": "4df32d6c-c90f-4794-9853-fa94cac9f4f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='Memory', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "searched_docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8rE0dp-IJ_1K"
      },
      "outputs": [],
      "source": [
        "# save DB\n",
        "db = Chroma.from_documents(docs, embeddings_model, persist_directory=\"./chroma_db\")\n",
        "\n",
        "# load DB\n",
        "db = Chroma(persist_directory=\"./chroma_db\", embedding_function=embeddings_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgOpLJxyEAJu"
      },
      "source": [
        "# User query와 retrieved chunk 에 대해 relevance 가 있는지를 평가하는 시스템 프롬프트 작성\n",
        "- retrieval 퀄리티를 LLM 이 스스로 평가하도록 하고, 관련이 있으면 {‘relevance’: ‘yes’} 관련이 없으면 {‘relevance’: ‘no’} 라고 출력하도록 함. (JsonOutputParser() 를 활용 ) - llama3 prompt format 준수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LzaW_2xKbKW",
        "outputId": "e3653008-9948-45d4-e49d-ec0a3bbe8986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.20-py3-none-any.whl.metadata (659 bytes)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchainhub) (24.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from langchainhub) (2.32.3)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.0.20240602-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/sol.ty/Desktop/workspace/ai-advanced/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (2024.6.2)\n",
            "Downloading langchainhub-0.1.20-py3-none-any.whl (5.0 kB)\n",
            "Downloading types_requests-2.32.0.20240602-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, langchainhub\n",
            "Successfully installed langchainhub-0.1.20 types-requests-2.32.0.20240602\n"
          ]
        }
      ],
      "source": [
        "!pip install langchainhub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcgBeVvxUfyw",
        "outputId": "79bc424f-bdfb-4854-c6a9-ab7592d57554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Memory', 'memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g.', 'Memory can be defined as the processes used to acquire, store, retain, and later retrieve', 'Long-term memory: This provides the agent with the capability to retain and recall (infinite)']\n"
          ]
        }
      ],
      "source": [
        "query =  \"agent momory\"\n",
        "\n",
        "searched_docs = vectorstore.similarity_search(query)\n",
        "contexts = [doc.page_content for doc in searched_docs]\n",
        "print(contexts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2B_X6ZbnElMa"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llama3_format_template = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
        "\n",
        "prompt_relevance = \"\"\"\n",
        "Check the <query> is relevant to retrieved <context>. Answer with \"yes\" or \"no\" in json format(key: relevance).\n",
        "\n",
        "<query>\n",
        "{query}\n",
        "</query>\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\"\"\"\n",
        "prompt_relevance_llama3 = llama3_format_template.format(prompt=prompt_relevance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3nJs4rWVdx",
        "outputId": "7e54451f-fc80-4aba-bca6-a4f92542be67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'relevance': 'yes'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "query = \"Memory\"\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    collection_name=\"sol_day2\",\n",
        "    documents=splits,\n",
        "    embedding=embeddings_model\n",
        "    )\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(prompt_relevance_llama3)\n",
        "model = ChatOpenAI(temperature=0)\n",
        "output_parser = JsonOutputParser()\n",
        "\n",
        "setup_and_retrieval = RunnableParallel(\n",
        "    {\"context\": retriever, \"query\": RunnablePassthrough()}\n",
        ")\n",
        "chain = setup_and_retrieval | prompt | model | output_parser\n",
        "answer = chain.invoke(query)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5daVA_hsRBOC"
      },
      "source": [
        "# 5 에서 모든 docs에 대해 ‘no’ 라면 디버깅\n",
        "(Splitter, Chunk size, overlap, embedding model, vector store, retrieval 평가 시스템 프롬프트 등)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCFcnLhCREvQ"
      },
      "source": [
        "# 5에서 ‘yes’ 라면 질문과 명확히 관련 없는 docs 나 질문\n",
        "(예: ‘I like an apple’에 대해서는 ‘no’ 라고 나오는지 테스트 프롬프트 및 평가 코드 작성. 이 때는 관련 없다는 답변 작성)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC049AS6-Zor",
        "outputId": "62d1a456-7453-41e0-d154-d6ab5ace2151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'relevance': 'yes'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "query = \"agent memory\"\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    collection_name=\"sol_day2\",\n",
        "    documents=splits,\n",
        "    embedding=embeddings_model\n",
        "    )\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(prompt_relevance_llama3)\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
        "output_parser = JsonOutputParser()\n",
        "\n",
        "setup_and_retrieval = RunnableParallel(\n",
        "    {\"context\": retriever, \"query\": RunnablePassthrough()}\n",
        ")\n",
        "chain = setup_and_retrieval | prompt | model | output_parser\n",
        "answer = chain.invoke(query)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3pXEBTtcM1g"
      },
      "source": [
        "# ‘yes’ 이고 7의 평가에서도 문제가 없다면, 4의 retrieved chunk 를 가지고 답변 작성\n",
        "\n",
        "- 막힌 부분: 랭체인이 relevance 여부와 retrieved chunk를 함께 내뱉게 만드는 방법."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsWt5qX2cMSA"
      },
      "source": [
        "# 생성된 답안에 Hallucination 이 있는지 평가하는 시스템 프롬프트 작성.\n",
        "LLM이 스스로 평가하도록 하고, hallucination 이 있으면 {‘hallucination’: ‘yes’} 없으면 {‘hallucination’: ‘no’} 라고 출력하도록 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84O4xuWWcYSe"
      },
      "source": [
        "# 9 에서 ‘yes’ 면 8 로 돌아가서 다시 생성,\n",
        "‘no’ 면 답변 생성하고 유저에게 답변 생성에 사용된 출처와 함께 출력\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 최종"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llama3_format_template = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
        "\n",
        "prompt_relevance = \"\"\"\n",
        "Check the <query> is relevant to retrieved <context>. Answer with \"yes\" or \"no\" in json format(key: relevance).\n",
        "\n",
        "<query>\n",
        "{query}\n",
        "</query>\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\"\"\"\n",
        "prompt_relevance_llama3 = llama3_format_template.format(prompt=prompt_relevance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "k2Eue9TPcYcI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Answer: Agent memory refers to the ability of an artificial intelligence (AI) or a software agent to store, retrieve, and utilize information from its previous interactions, experiences, and observations to inform its future decisions and behaviors.\n",
            "==================================================\n",
            "Context 1\n",
            "page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.' metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}\n",
            "Content: The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\n",
            "Source: https://lilianweng.github.io/posts/2023-06-23-agent/\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "    ]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=50,\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    embedding=embeddings_model,\n",
        "    collection_name=\"sol_day2\",\n",
        "    persist_directory=\"./chroma_db\",\n",
        ")\n",
        "\n",
        "query = \"llm agent memory\"\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "# Common setting for chains\n",
        "local_llm = \"llama3\"\n",
        "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
        "parser = JsonOutputParser()\n",
        "\n",
        "# Relevance check\n",
        "prompt = PromptTemplate(\n",
        "    template=llama3_format_template.format(\n",
        "        prompt=\"\"\"Check the <query> is relevant to retrieved <context>. Answer with \"yes\" or \"no\" in json format(key: relevance).\n",
        "        Here is the question: {query}\n",
        "        Here is the context: {context}\"\"\"\n",
        "    ),\n",
        "    input_variables=[\"query\", \"context\"],\n",
        ")\n",
        "relevant_chain = prompt | llm | parser\n",
        "valid_doc_list = []\n",
        "for doc in docs:\n",
        "    doc_text = doc.page_content\n",
        "    is_relevant = relevant_chain.invoke({\"query\": query, \"context\": doc_text})[\"relevance\"]\n",
        "    if is_relevant == \"yes\":\n",
        "        valid_doc_list.append(doc)\n",
        "\n",
        "# Drop duplicate in context\n",
        "context_list = []\n",
        "for doc in valid_doc_list:\n",
        "    if doc.page_content not in [context.page_content for context in context_list]:\n",
        "        context_list.append(doc)\n",
        "\n",
        "# If context_list is not empty\n",
        "if context_list:\n",
        "    while 1:\n",
        "        # Answer\n",
        "        context = \"\\n\".join([doc.page_content for doc in context_list])\n",
        "        prompt = PromptTemplate(\n",
        "            template=llama3_format_template.format(\n",
        "                prompt=\"\"\"Answer to the <query> with <context>. Answer in json format(key: answer).\n",
        "                Here is the question: {query}\n",
        "                Here is the context: {context}\"\"\"\n",
        "            ),\n",
        "            input_variables=[\"query\", \"context\"],\n",
        "        )\n",
        "        question_chain = prompt | llm | parser\n",
        "        answer = question_chain.invoke(\n",
        "            {\"query\": \"What is agent memory?\", \"context\": context}\n",
        "            )[\"answer\"]\n",
        "        \n",
        "        # Halucination check\n",
        "        hallucination_prompt = PromptTemplate(\n",
        "            template=llama3_format_template.format(\n",
        "                prompt=\"\"\"Check the <answer> has halllucination or not. Answer with \"yes\" or \"no\" in json format(key: hallucination).\n",
        "                Here is the answer: {answer}\"\"\"\n",
        "            ),\n",
        "            input_variables=[\"answer\"],\n",
        "        )\n",
        "        hallucination_chain = hallucination_prompt | llm | parser\n",
        "        hallucination = hallucination_chain.invoke({\"answer\": answer})[\"hallucination\"]\n",
        "\n",
        "        if hallucination == \"no\":\n",
        "            break    \n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Answer: {answer}\")\n",
        "    for idx, context in enumerate(context_list):\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Context {idx+1}\")\n",
        "        print(context)\n",
        "        print(f\"Content: {context.page_content}\")\n",
        "        print(f\"Source: {context.metadata['source']}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "else:\n",
        "    print(\"No\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
